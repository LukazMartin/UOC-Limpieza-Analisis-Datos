---
title: 'PRÁCTICA 2: ¿Cómo realizar la limpieza y análisis de datos?'
author: "Lukaz Martin Doehne y Pablo Vadillo Berganza"
date: "08/01/2023"
output:
  pdf_document:
    toc: true
    toc_depth: 3
lang: es
tuthor: Laia Subirats Maté
---

\pagebreak

# 1.Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

En primer lugar, cargaremos los datos con los que trabajar.

```{r echo=FALSE}
df <- read.csv('../data/heart.csv')
```

Nuestro dataset está compuesto por 303 registros y 14 variables. Contiene información clínica de pacientes con el fin de poder predecir la probabilidad de fallo cardíaco. 


Para ello, la variable a predecir, "output", contiene información acerca del estrechamiento de los vasos sanguíneos obtenida a través de una angiografía. Si el estrechamiento es inferior al 50% toma el valor 0 y por tanto el paciente no se considera en riesgo de padecer una enfermedad del corazón. Por el contrario, si el estrechamiento es superior al 50%, la variable tomará el valor 1 y el paciente tendrá una mayor probabilidad de ataque al corazón.


A partir de aquí, será interesante realizar un análisis del resto de campos para ver cuáles son determinantes en la predicción del fallo cardíaco. Estudiar correlaciones, así como diferencias en la probabilidad del fallo cardíaco en diferentes grupos...


Pero antes, vamos a realizar una breve exploración del dataset.

```{r}
str(df)
```

Todas las variables son numéricas.

```{r}
summary(df)
```

Para terminar con este apartado, vamos a explicar brevemente todos y cada uno de los campos del dataset:

  · Age: Edad de los pacientes en años. Toma valores entre 29 y 77. La media es 54,37.
  
  · Sex: Sexo de los pacientes. (1 = hombre; 0 = mujer).
  
  · Cp: Dolor de pecho. (1 = angina típica; 2 = angina atípica; 3 = dolor no anginal; 4 = asintomático).
  
  · Trtbps: Presión arterial en reposo. Se trata del valor tomado en el ingreso al hospital, en mm Hg. Toma valores entre 94 y 200, siendo la media de 131,6.
  
  · Chol: Colesterol sérico. Medido en mg/dl. Toma valores entre 126 y 564, con una media de 246,3.
  
  · Fbs: Nivel de azúcar en sangre en ayunas. (1 = > 120 mg/dl; 0 = <= 120 mg/dl).
  
  · Restecg: Resultados del electrocardiograma en reposo. (0 = normal; 1 = onda ST-T anómala; 2 = hipertrofia ventricular izquierda).
  
  · Thalachh: Máximo pulso cardíaco obtenido. Toma valores entre 71 y 202. La media es 149,6.
  
  · Exng: Angina inducida del ejercicio. (1 = sí; 0 = no).
  
  · Oldpeak: Depresión del segmento ST inducida por ejercicio relativo al descanso. Toma valores entre 0 y 6,2, con una media de 1,04.
  
  · Slp: Pendiente del segmento ST del pico del ejercicio. (1 = ascendente; 2 = plano; 3 = descendente).
  
  · Caa: Número de los principales vasos sanguíneos coloreados por la fluoroscopia. Toma valores entre 0 y 4, con una media de 0,73.
  
  · Thall: Talasemia. Menor nivel de hemoglobina. (1 = defecto fijo; 2 = normal; 3 = defecto reversible). El defecto fijo hace referencia a un defecto que ocurre tanto en reposo como durante el esfuerzo. El defecto reversible, por el contrario, hace referencia a un defecto que ocurre durante el esfuerzo que no existía durante el reposo.

  · Output: La variable a predecir. Diagnóstico de fallo cardíaco (0 = Estrechamiento de vasos sanguíneos < 50%; 1 = Estrechamiento de vasos sanguíneos > 50%).

# 2.Integración y selección 

En este apartado analizaremos qué campos son realmente significativos a la hora de predecir la variable output.

En primer lugar, calcularemos los coeficientes de correlación de Pearson, y nos fijaremos expresamente en la variable a predecir, output, con el resto de variables independientes.

```{r}
cor_pearson <- cor(df)

# Mostramos los valores de output con el resto,

cor_pearson[14,]
```

Las variables chol (colesterol sérico) y fbs (nivel de azúcar en sangre en ayunas) presentan un coeficiente por debajo del 0.1 (en valor absoluto), por lo que podemos concluir que la correlación con la variable a predecir es prácticamente inexistente, y podemos prescindir de estas variables de cara al análisis.


Para acabar con este apartado, haremos un análisis de componentes principales, para detectar cuáles son las variables que realmente describen el conjunto de datos.

Pero antes, descargaremos las librerías necesarias,

```{r echo=TRUE, message=FALSE, warning=FALSE}
#if (!require('FactoMineR')) install.packages('FactoMineR'); library('FactoMineR')
#if (!require('factoextra')) install.packages("factoextra"); library('factoextra')
```

A continuación, realizamos el test de PCA,

```{r}
#PCA <- PCA(df, graph=FALSE)

# Contribuciones de las variables a PC1,
#fviz_contrib(PCA, choice = "var", axes = 1, top = 14)
# Contribuciones de las variables a PC2,
#fviz_contrib(PCA, choice = "var", axes = 2, top = 14)
```

En estos gráficos podemos ver el nivel de contribución de cada una de las variables a las 2 primeras dimensiones de las componentes principales. Seleccionamos las dos primeras dimensiones ya que las variables que estén correlacionadas con éstas serán las que sean capaces de explicar todo el dataset.


Las variables output, oldpeak, thalachh, exng, slp y cp contribuyen más que la media de contribución esperada (línea roja) para la dimensión 1. Sin embargo, caa, age y thall también contribuyen de forma no despreciable. Las variables trtbps, sex, restecg, chol y fbs son las que menos contribuyen a la dimensión 1.


Si vamos a la dimensión 2, tenemos que age, trtbps, sex, chol, fbs y cp contribuyen más que la media de contribución esperada.

Viendo la perspectiva para las dos primeras dimensiones, vemos que la variable restecg (Resultado de electrocardiograma en reposo) es la que menos contribuye. Además, volviendo al coeficiente de correlación de Pearson, después de chol y fbs, también es la que menor coeficiente, en valor absoluto, presenta.


En conclusión, prescindiremos de las variables chol y fbs por presentar una correlación prácticamente inexistente con la variable a predecir, output. Por otro lado, también prescindimos del campo restecg ya que es el que menos contribuye a la variabilidad del dataset, además de presentar una correlación débil con la variable a predecir.


```{r}
col <- c(1,2,3,4,8,9,10,11,12,13,14)

df_def <- df[,col]
```



\pagebreak
# 3. Limpieza de los datos

## 3.1. ¿Los datos contienen ceros o elementos vacíos? 

Ante elementos vacíos se pueden seguir principalmente dos estrategias: la **imputación** y la **eliminación**.

Para la primera, se trata de rellenar los valores nulos basandose en los valores no vacíos. Esto se realizar típicamente mediante *knn*, interpolación o cogiendo la media de una columna.

La segunda estrategía consiste en eliminar las filas con valores nulos. Esta se suele usar cuando se tiene un dataset grande y los valores nulos no suponen un gran porcentaje.

Podemos comprobar que no se encuentran elementos nulos en el csv con el siguiente código:

```{r}
sapply(df, function(x) sum(is.na(x)))
```

Dado que no encontramos valores nulos no aplicamos ninguna de las estrategias. Pero vamos a discretizar la columna *age* para mejor procesamiento.

**Discretización**

Para la variable edad, en lugar de tener el valor exacto crearemos grupos por decenas de edad.

E.g:

·30-39 -> 3

·40-49 -> 4

...

```{r echo=FALSE}
df$age[df$age >= 20 & df$age<30] = 2
df$age[df$age >= 30 & df$age<40] = 3
df$age[df$age >= 40 & df$age<50] = 4
df$age[df$age >= 50 & df$age<60] = 5
df$age[df$age >= 60 & df$age<70] = 6
df$age[df$age >= 70 & df$age<80] = 7
```

Vemos el resultado


```{r echo=FALSE}
table(df$age)
```



## 3.2. Identifica y gestiona los valores extremos

Los valores extremos (*outliers*) los identificaremos como aquellos que se encuentran fuera del rango [Lo,Ho] donde:

  · Lo = Q1 – (1.5 * IQR) 
  
  · Ho = Q3 + (1.5 * IQR)
  
y IQR = Q3 - Q1. También hay una fórmula que trata outliers los que sobrepasan la media +/- la desviación estándar, pero optaremos por la fórmula descrita, ya que también es la que usa *R* por defecto en la función boxplot.

A continuación, mostramos la cantidad de outliers por columna con la siguiente función:

```{r}
outliers<-function(x){
  outliers<-boxplot.stats(x)$out
  return (length(outliers))
}
```

```{r echo=FALSE}
sapply(df, function(x) outliers(x))
```

Encontramos varios outliers en los datos. Las columnas *fbs*, *caa* y *thall* son columnas **númericas discretas** por lo que no los consideramos outliers, sino solo un dataset desequilibrado.

Visualizamos para entender mejor las demás variables.

```{r echo=FALSE}
boxplot(df$trtbps,df$chol,df$thalachh, names =c("trtbps","chol","thalachh"), col=c("blue","red","green"))
```

La variable *oldpeak* la visualizamos en un histograma al estar en una escala diferente a las demás.

```{r echo=FALSE}
h<-hist(df$oldpeak,plot=FALSE)
plot(h, xaxt = "n", xlab = "Oldpeak Histogram", ylab = "Counts", main = "", col = "pink")
```


Viendo las visualizaciones suponemos que no ha habido errores a la hora de capturar los datos. Si que es cierto que en la columna *chol* encontramos un valor muy alejado del valor medio, pero lo mantendremos dentro del analisis al igual que el resto de los outliers. Si creamos un modelo de predicción podemos asegurar de incluir los outliers tanto en el train como en el test set.
\pagebreak

# 4. Análisis de los datos

## 4.1. Selección de los grupos de datos que se quieren analizar/compara

Hay 3 grupos en especial que nos interesa estudiar en función del fallo cardíaco:

· La variable **sex**. En función de hombres y mujeres.

· La variable **age**. En función de la edad de los pacientes.

· La variable **trtbps**. En función de la presión arterial de los pacientes. Información extraída de: [mayoclinic.org](https://www.mayoclinic.org/es-es/diseases-conditions/high-blood-pressure/diagnosis-treatment/drc-20373417#:~:text=Presi%C3%B3n%20arterial%20normal,de%20emergencia%20local.)

· La variable **output**. En función de la probabilidad de fallo cardíaco.


```{r}
# Agrupación por género
df.male <- df[df$sex == 1,]
df.female <- df[df$sex == 0,]
# Agrupación por edad
df.young_adult <- df[df$age<4,]
df.adult <- df[df$age>=4&df$age<6,]
df.old_adult <- df[df$age>=6,]
# Agrupación por presión arterial
df.normal_pressure <- df[df$trtbps<120,]
df.high_pressure <- df[df$trtbps>=120&df$trtbps<130,]
df.hipertension1 <- df[df$trtbps>=130&df$trtbps<140,]
df.hipertension2 <- df[df$trtbps>=140&df$trtbps<180,]
df.crisis_hipertension <- df[df$trtbps>=180,]
# Agrupación por fallo cardíaco
df.high_output <- df_def[df_def$output == 1,]
df.low_output <-df_def[df_def$output == 0,]
```




## 4.2. Comprobación de la normalidad y homogeneidad de la varianza


Estudiamos la normalidad de la variable age y trtbps según la variable output, para ello, graficamos los QQplots que nos permiten observar similitudes con una distribución normal,


```{r}
qqnorm(df.high_output$age)
qqline(df.high_output$age,col=2)
qqnorm(df.low_output$age)
qqline(df.low_output$age,col=2)
```

Visualmente, la variable age parece comportarse como una normal a partir de los gráficos, no obstante, realizaremos el test Shapiro para asegurarnos de que esto es cierto,

```{r}
shapiro.test(df.high_output$age)
shapiro.test(df.low_output$age)
```

A partir del test de Shapiro-Wilk, podemos asumir que la variable edad para los pacientes con output = 1 sigue una distribución normal, ya que el p-valor es mayor que 0.05 (nivel de significancia normalmente utilizado), si bien para los pacientes con output = 0 esto no es cierto ya que el p-valor es menor.

Como no podemos asumir normalidad para el conjunto de pacientes con output = 0, comprobamos igualdad de varianzas a partir del test fligner:


```{r}
fligner.test(age ~ output, data = df_def)
```

De nuevo, tenemos un p-valor menor a 0.05, por lo que rechazamos la hipótesis nula de que las varianzas son iguales para ambos conjuntos.

Volvemos a hacer el mismo ejercicio, pero ahora para la variable trtbps,

```{r}
qqnorm(df.high_output$trtbps)
qqline(df.high_output$trtbps,col=2)
qqnorm(df.low_output$trtbps)
qqline(df.low_output$trtbps,col=2)
```

De nuevo, tenemos que la variable trtbps parece comportarse como una normal a partir de los gráficos, no obstante, realizaremos el test Shapiro para asegurarnos de que esto es cierto,

```{r}
shapiro.test(df.high_output$trtbps)
shapiro.test(df.low_output$trtbps)
```

A partir del test de Shapiro-Wilk, tenemos que la variable trtbps no presenta una distribución normal en ninguno de los conjuntos, siendo sobre todo evidente en los pacientes con output = 0.

Como no podemos asumir normalidad, comprobamos igualdad de varianzas a partir del test fligner:

```{r}
fligner.test(trtbps ~ output, data = df_def)
```

Obtenemos un p-valor de 0.243, por tanto no estamos en condiciones de rechazar la hipótesis nula y concluimos que las varianzas son similares para pacientes con output 1 y 0.


## 4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos

El primer test a realizar será un contraste sobre la proporción de una muestra. Queremos ver si hay diferencias en la proporción de pacientes con output = 1 entre hombres y mujeres.

Para ello, en primer lugar realizaremos un gráfico para ver visualmente cómo está distribuida nuestra muestra,

Pero antes, descargamos ciertas librerías necesarias,

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if (!require('gridExtra')) install.packages("gridExtra"); library('gridExtra')
if (!require('scales')) install.packages('scales'); library('scales')
```


```{r}
ggplot(df_def, aes(x = output, group = sex))+geom_bar(aes(y = ..prop.., fill = factor(..x..)))+geom_text(aes( label = percent(..prop.., accuracy=0.1), y= ..prop.. ), stat= "count", vjust = -.25) + labs(y = "Porcentaje", fill="Output") +facet_grid(~sex) + scale_y_continuous(labels = percent) +ggtitle("Porcentaje de pacientes según output en función del género")
```

Según lo visualizado, entre las mujeres, el 75% presenta un output 1, mientras que entre los hombres sólo un 44,9%. Esto parece indicar que las mujeres presentan una mayor probabilidad de fallo cardíaco.


Por tanto, nuestra hipótesis nula será la igualdad de proporción de pacientes con output 1 entre hombres y mujeres, y la hipótesis alternativa que la proporción de pacientes con output 1 es mayor en mujeres que en hombres.

Aplicamos un contraste sobre la diferencia de proporciones, asumiendo la aproximación de la distribución binomial a una normal para muestras grandes. Se trata de un contraste unilateral por la derecha.

```{r}
summary(factor(df.male$output))
summary(factor(df.female$output))
```

Dentro de las mujeres (96), (72) tienen una probabilidad alta de fallo cardíaco.

Entre los hombres (207), (93) tienen una probabilidad alta de fallo cardíaco.

Aplicamos el test,

```{r}
prop.test(x = c(72,93), n = c(96,207), alternative="greater", correct = FALSE)
```

El p-valor es muy pequeño, por lo que rechazamos la hipótesis nula de igualdad de proporciones, y aceptamos la hipótesis de que las mujeres tienen un mayor probabilidad de fallo cardíaco.


A continuación, vamos a realizar dos tests de dos muestras independientes (según output) para descubrir si hay diferencias entre las variables age y trtbps.


En el apartado anterior ya vimos que no podíamos asumir normalidad en ninguno de los casos, por lo que aplicamos un test no paramétrico como el de Wilcoxon,

```{r}
wilcox.test(df_def$age~df_def$output)
wilcox.test(df_def$trtbps~df_def$output)
```

En ambos casos tenemos que el p-valor es menor a 0.05, por lo que rechazamos la hipótesis nula y asumimos que existen diferencias significativas en la edad y en la presión arterial de los pacientes según su probabilidad de fallo cardíaco.

Finalmente, podemos generar un modelo de regresión logística para predecir el valor de la variable output.


Para ello, dividimos el dataset en un conjunto de entrenamiento y otro de test:

```{r}
set.seed(1)

sample <- sample(c(TRUE, FALSE), nrow(df_def), replace=TRUE, prob=c(0.8,0.2))
df.train  <- df_def[sample, ]
df.test   <- df_def[!sample, ]
```

Y creamos el modelo a partir del conjunto de entrenamiento,

```{r}
Modlg <- glm(output ~ age + sex + cp + trtbps + thalachh + exng + oldpeak + slp + caa + thall, data = df.train, family = binomial)
summary(Modlg)
```

A continuación, generaremos la matriz de confusión para ver qué tal predice nuestro modelo, para ello haremos uso del conjunto de test.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('caret')) install.packages('caret'); library('caret')
```

```{r}
prediction1 <- data.frame(predict(Modlg, df.test[,1:10], type = "response"))
prediction2 <- data.frame(ifelse(prediction1 < 0.5, 0, 1))

confusionMatrix(data=as.factor(prediction2$predict.Modlg..df.test...1.10...type....response..), reference=as.factor(df.test$output))
```

Nuestro modelo tiene un porcentaje de acierto del 73,47%. Si hablamos de predecir a los pacientes con mayor probabilidad de infarto (output = 1), esta probabilidad sube hasta el 80,77%.


# 5. Representación de los resultados a partir de tablas y gráficas

# 6. Resolución del problema

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars, echo=FALSE}
summary(cars)
```

